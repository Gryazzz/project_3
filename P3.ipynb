{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html  \n",
    "import json\n",
    "import requests\n",
    "import json,re\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "import random\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tor handler class\n",
    "# from here: https://github.com/bdheath/pytor\n",
    "import stem\n",
    "from stem.control import Controller\n",
    "from stem import Signal\n",
    "#import mechanize\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "class pytor:\n",
    "    controlPort = 9051\n",
    "    port = 9050\n",
    "    host = 'localhost'\n",
    "    password = 'Password'\n",
    "    _version = 0.1\n",
    "    _last_result = None\n",
    "    _last_request = None\n",
    "    _id_time = 60\n",
    "    _last_id_time = None\n",
    "    _ip = None\n",
    "    _connected = False\n",
    "    browser = None\n",
    "    controller = False\n",
    "    _h = None\n",
    "    _proxies = {}\n",
    "\n",
    "    def __init__(self, host='localhost', port=9050, controller=True, controlPort = 9051):#, password=''):\n",
    "        self.controlPort = controlPort\n",
    "        self.port = port\n",
    "        self.controller = controller\n",
    "        self._proxies['http'] = 'socks5://localhost:' + str(self.port)\n",
    "        self._proxies['https'] = 'socks5://localhost:' + str(self.port)\n",
    "        if self.controller:\n",
    "            self.torControl = Controller.from_port(port=controlPort)\n",
    "            self.torControl.authenticate(self.password)\n",
    "            self._connected = True\n",
    "        self._last_id_time = datetime.datetime.now()\n",
    "        return\n",
    "\n",
    "    def request(self, url, h, timeout = 30):\n",
    "        self._checkIdentityTime()\n",
    "        r = requests.get(url, headers=h, timeout=timeout, proxies=self._proxies)\n",
    "        print(f'GET through TOR the: {r.url}')\n",
    "        self._last_request = url\n",
    "        self._last_result = r.text\n",
    "        return r\n",
    "\n",
    "    def get(self, url, h=None, t=30):\t\t\n",
    "        self._checkIdentityTime()\n",
    "\n",
    "        r = self.request(url, h, timeout = t)\n",
    "        print(f'Status code: {r.status_code}')\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            self._last_result = r.text\n",
    "            self._last_request = url\n",
    "            return self._last_result\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def ip(self):\n",
    "        #self._ip = self.get('http://bradheath.org/ip', self._h)\n",
    "        self._ip = self.get('https://api.ipify.org', self._h)\n",
    "        return self._ip\n",
    "\n",
    "    def timeForNew(self):\n",
    "        self._checkIdentityTime()\n",
    "        return\t\t\n",
    "        \n",
    "    def saveLastResult(file):\n",
    "        with open(file, 'wb') as local_file:\n",
    "            local_file.write(self._last_result)\n",
    "        return\n",
    "\n",
    "    def downloadFile(self, url, file):\n",
    "        self._checkIdentityTime()\n",
    "        r = requests.get(url, stream = True, proxies = self._proxies)\n",
    "        with open(file, 'wb') as local_file:\n",
    "            for chunk in r.iter_content ( chunk_size = 1024):\n",
    "                if chunk:\n",
    "                    local_file.write(chunk)\n",
    "        self._last_request = url\n",
    "        return True\n",
    "\n",
    "    def newIdentity(self):\n",
    "        print(\"## NEW IDENTITY ## \")\n",
    "        if not self._connected:\n",
    "            self.torControl = Controller.from_port(port=self.controlPort)\n",
    "            self.torControl.authenticate(self.password)\n",
    "            self._connected = True\n",
    "        self.torControl.authenticate(self.password)\n",
    "        self.torControl.signal(Signal.NEWNYM)\n",
    "        self._last_id_time = datetime.datetime.now()\n",
    "        return True\n",
    "\n",
    "    def _checkIdentityTime(self):\n",
    "        if self._id_time != None and self._last_id_time != None:\n",
    "            if (datetime.datetime.now() - self._last_id_time).seconds >= self._id_time:\n",
    "                print('Getting new identity')\n",
    "                self.newIdentity()\n",
    "        return\n",
    "\n",
    "    def identityTime(self, time = 600):\n",
    "        self._id_time = time\n",
    "        return\n",
    "\n",
    "#\t'''def mechanizeBrowser(self):\n",
    "#\t\tself.browser = mechanize.Browser()\n",
    "#\t\treturn self.browser'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers generator\n",
    "def getHeaders():\n",
    "    user_agents = ['Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/525.19 (KHTML, like Gecko) Chrome/1.0.154.53 Safari/525.19','Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/525.19 (KHTML, like Gecko) Chrome/1.0.154.36 Safari/525.19','Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.10 (KHTML, like Gecko) Chrome/7.0.540.0 Safari/534.10','Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/534.4 (KHTML, like Gecko) Chrome/6.0.481.0 Safari/534.4','Mozilla/5.0 (Macintosh; U; Intel Mac OS X; en-US) AppleWebKit/533.4 (KHTML, like Gecko) Chrome/5.0.375.86 Safari/533.4','Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/532.2 (KHTML, like Gecko) Chrome/4.0.223.3 Safari/532.2','Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.0 (KHTML, like Gecko) Chrome/4.0.201.1 Safari/532.0','Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.0 (KHTML, like Gecko) Chrome/3.0.195.27 Safari/532.0','Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/530.5 (KHTML, like Gecko) Chrome/2.0.173.1 Safari/530.5','Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/534.10 (KHTML, like Gecko) Chrome/8.0.558.0 Safari/534.10','Mozilla/5.0 (X11; U; Linux x86_64; en-US) AppleWebKit/540.0 (KHTML,like Gecko) Chrome/9.1.0.0 Safari/540.0','Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.600.0 Safari/534.14','Mozilla/5.0 (X11; U; Windows NT 6; en-US) AppleWebKit/534.12 (KHTML, like Gecko) Chrome/9.0.587.0 Safari/534.12','Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.13 (KHTML, like Gecko) Chrome/9.0.597.0 Safari/534.13','Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.11 Safari/534.16','Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20','Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.792.0 Safari/535.1','Mozilla/5.0 (Windows NT 5.1) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.872.0 Safari/535.2','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7','Mozilla/5.0 (Windows NT 6.0; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.66 Safari/535.11','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.45 Safari/535.19','Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24','Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1','Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.15 (KHTML, like Gecko) Chrome/24.0.1295.0 Safari/537.15','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36','Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1467.0 Safari/537.36','Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1623.0 Safari/537.36','Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.116 Safari/537.36','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.103 Safari/537.36','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.38 Safari/537.36','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.71 Safari/537.36','Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36','Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.62 Safari/537.36']\n",
    "    headers = {'User-Agent': user_agents[random.randint(0,len(user_agents)-1)]}\n",
    "    return headers\n",
    "\n",
    "#parser function\n",
    "def getParser(url, headers, t=tor):\n",
    "    #print(f'IP: {tor.ip()}')\n",
    "    page = t.get(url,headers)\n",
    "    \n",
    "    if page:\n",
    "        parser = html.fromstring(page)\n",
    "        print(f'getParser: Returning {parser}')\n",
    "        return parser\n",
    "    else:\n",
    "        print('getParser: Unable to parse page')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting product info function\n",
    "def getProductInfo(asin):\n",
    "    \n",
    "    #setup url to parse\n",
    "    amazon_url  = 'http://www.amazon.com/dp/'+asin\n",
    "        \n",
    "    #obtain parsed page\n",
    "    parser = getParser(amazon_url, getHeaders())\n",
    "    \n",
    "    if not parser:\n",
    "        print(\"Has not received parser.\")\n",
    "        return False\n",
    "    \n",
    "    #set xpaths\n",
    "    xpath_product_name     = '//h1//span[@id=\"productTitle\"]//text()'\n",
    "    xpath_product_price    = '//span[@id=\"priceblock_ourprice\"]/text()'\n",
    "    xpath_bullets          = '//div[@id=\"fbExpandableSectionContent\"]//li/span/text()'\n",
    "    xpath_description      = '//div[@id=\"productDescription\"]//p/text()'\n",
    "    xpath_description_2    = '//div[contains(@class,\"aplus-module\")]//p/text()'\n",
    "    xpath_reviews_count    = '//span[@id=\"acrCustomerReviewText\"]//text()'\n",
    "    xpath_rating_count     = '//span[contains(@class,\"reviewCountTextLinkedHistogram\")]/@title'\n",
    "    xpath_variation_flavor = '//div[@id=\"shelfSwatchSection-flavor_name\"]//span[contains(@class,\"twisterShelf_swatch_text\")]/text()'\n",
    "    xpath_variation_size   = '//div[@id=\"shelf-size_name\"]//span[contains(@class,\"twisterShelf_swatch_text\")]/text()'\n",
    "    xpath_seller_rank = '//li[@id=\"SalesRank\"]/text()'\n",
    "    xpath_main_category_url = '//li[@id=\"SalesRank\"]/a/@href'\n",
    "    \n",
    "    #extract raw data\n",
    "    raw_product_name          = parser.xpath(xpath_product_name)\n",
    "    raw_product_price         = parser.xpath(xpath_product_price)\n",
    "    raw_product_bullets       = parser.xpath(xpath_bullets)\n",
    "    raw_product_description   = parser.xpath(xpath_description)\n",
    "    raw_product_description_2 = parser.xpath(xpath_description_2)\n",
    "    raw_reviews_count         = parser.xpath(xpath_reviews_count)\n",
    "    raw_rating                = parser.xpath(xpath_rating_count)\n",
    "    raw_variation_flavor      = parser.xpath(xpath_variation_flavor)\n",
    "    raw_variation_size        = parser.xpath(xpath_variation_size)\n",
    "    raw_seller_rank           = parser.xpath(xpath_seller_rank)\n",
    "    raw_main_category         = parser.xpath(xpath_main_category)\n",
    "    raw_main_category_url     = parser.xpath(xpath_main_category_url)\n",
    "    \n",
    "    #cleaning data\n",
    "    product_name     = ''.join(raw_product_name).strip()\n",
    "    product_price    = ''.join(raw_product_price).replace(',','').replace('$','')\n",
    "    variation_flavor = ' '.join(','.join(raw_variation_flavor).split())\n",
    "    variation_size   = ' '.join(','.join(raw_variation_size).split())\n",
    "   \n",
    "    if raw_product_description_2:\n",
    "        product_description = ' '.join(' '.join(raw_product_description_2).split())\n",
    "    else:\n",
    "        product_description = ' '.join(' '.join(raw_product_description).split())\n",
    "\n",
    "    product_bullets = {}\n",
    "    for i in range(len(raw_product_bullets)):\n",
    "        product_bullets['Bullet '+str(i+1)] = ' '.join(raw_product_bullets[i].split())\n",
    "        \n",
    "    if raw_reviews_count:\n",
    "        reviews_count = ' '.join(raw_reviews_count).split()[0]\n",
    "    else:\n",
    "        reviews_count = 0\n",
    "    \n",
    "    if raw_rating:\n",
    "        rating = ' '.join(raw_rating).split()[0]\n",
    "    else:\n",
    "        rating = None\n",
    "        \n",
    "    if raw_main_category:\n",
    "        seller_rank   = ''.join(raw_seller_rank).split()[0].replace('#','').replace(',','')\n",
    "        main_category = ' '.join(''.join(raw_seller_rank).split()[2:-1])\n",
    "        main_category_url = raw_main_category_url[0]\n",
    "    \n",
    "    #create results dictionary\n",
    "    results = {\n",
    "        'ASIN'             :asin,\n",
    "        'Name'             :product_name,\n",
    "        'Price'            :product_price,\n",
    "        'Flavours'         :variation_flavor,\n",
    "        'Sizes'            :variation_size,\n",
    "        'Rating'           :rating,\n",
    "        'Reviews'          :reviews_count,\n",
    "        'URL'              :amazon_url, \n",
    "        'Description'      :product_description,\n",
    "        'Best Seller Rank' :seller_rank,\n",
    "        'Main Category'    :main_category,\n",
    "        'Main Category URL':main_category_url\n",
    "        }\n",
    "    \n",
    "    #add product bullets so later DF will treat those as columns on the same line\n",
    "    results.update(product_bullets)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting reviews function\n",
    "def getProductReviews(asin, pageNumber=1):    \n",
    "    #setup resulting list\n",
    "    reviews_list = []\n",
    "    \n",
    "    #setup url to parse\n",
    "    review_url = 'https://www.amazon.com/product-reviews/'+asin+'?pageNumber='+str(pageNumber)+'&sortBy=recent'\n",
    "    \n",
    "    #obtain parsed page\n",
    "    parser = getParser(review_url, getHeaders())\n",
    "    \n",
    "    #setup xpaths\n",
    "    xpath_reviews           = '//div[@data-hook=\"review\"]'\n",
    "    xpath_no_review_section = '//div[contains(@class,\"no-reviews-section\")]//text()'\n",
    "    \n",
    "    #parse reviews\n",
    "    reviews = parser.xpath(xpath_reviews)\n",
    "    \n",
    "    if not reviews:\n",
    "        print('getProductReviews: Unable to find reviews in page')\n",
    "        return reviews_list\n",
    "    \n",
    "    #parse end of reviews\n",
    "    no_review = parser.xpath(xpath_no_review_section)\n",
    "    if no_review:\n",
    "        print('getProductReviews: End of reviews')\n",
    "        return reviews_list\n",
    "\n",
    "    #setup the rest of xpaths\n",
    "    xpath_rating  = './/i[@data-hook=\"review-star-rating\"]//text()' \n",
    "    xpath_title   = './/a[@data-hook=\"review-title\"]//text()'\n",
    "    xpath_author  = './/a[@data-hook=\"review-author\"]//text()'\n",
    "    xpath_date    = './/span[@data-hook=\"review-date\"]//text()'\n",
    "    xpath_body    = './/span[@data-hook=\"review-body\"]//text()'\n",
    "    xpath_helpful = './/span[@data-hook=\"helpful-vote-statement\"]//text()'\n",
    "    \n",
    "    #process individual reviews\n",
    "    for review in reviews:\n",
    "        #DO review-comments section\n",
    "        review_comments = {}\n",
    "        \n",
    "        #cleaning data\n",
    "        rating  = ''.join(review.xpath(xpath_rating)).replace('out of 5 stars','')\n",
    "        title   = ' '.join(' '.join(review.xpath(xpath_title)).split())\n",
    "        author  = ' '.join(' '.join(review.xpath(xpath_author)).split())\n",
    "        date    = review.xpath(xpath_date)\n",
    "        body    = ' '.join(' '.join(review.xpath(xpath_body)).split())\n",
    "        helpful = ' '.join(' '.join(review.xpath(xpath_helpful)).split())\n",
    "        \n",
    "        #convert date\n",
    "        try:\n",
    "            review_posted_date = dateparser.parse(''.join(date)).strftime('%d %b %Y')\n",
    "        except:\n",
    "            review_posted_date = date\n",
    "        \n",
    "        review_dict = {'rating' : rating,\n",
    "                   'title'  : title,\n",
    "                   'author' : author,             \n",
    "                   'date'   : review_posted_date,\n",
    "                   'body'   : body,\n",
    "                   'helpful': helpful,\n",
    "                   'ASIN'   : asin\n",
    "                    }\n",
    "        review_dict.update(review_comments)\n",
    "        reviews_list.append(review_dict)\n",
    "    \n",
    "    return reviews_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of ASINs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AsinList = ['B016OP6N3M','B0723FXC74','B002M782UO','B01HN7ZGUQ','B000CBOTQ8',\n",
    "            'B014HPPAFS','B01GP2MTXW','B000AAM0EY','B000AAM0G2','B01LZFRZWH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting TOR object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed for switching identities\n",
    "#needed to switch identities every 10 minutes\n",
    "tor = pytor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting product info\n",
    "def ReadAsins(AsinList):\n",
    "    #list of columns for resulting CSV file\n",
    "    column_names = ['ASIN','URL','Name','Price','Flavours','Sizes','Rating','Reviews','Description',\n",
    "     'Bullet 1','Bullet 2','Bullet 3','Bullet 4',\n",
    "     'Bullet 5','Bullet 6','Bullet 7','Bullet 8']\n",
    "    \n",
    "    for asin in AsinList:\n",
    "        print(\"Downloading and processing \"+asin)\n",
    "        \n",
    "        results = getProductInfo(asin)\n",
    "        print(results)\n",
    "\n",
    "        if results:\n",
    "            df = pd.DataFrame(results, index=[0], columns=column_names)\n",
    "\n",
    "            # if file does not exist write header \n",
    "            if not os.path.isfile('products.csv'):\n",
    "                df.to_csv('products.csv',index=False, )\n",
    "            else: # else it exists so append without writing the header\n",
    "                df.to_csv('products.csv',mode = 'a',header=False,index=False, columns=column_names)\n",
    "        #sleep(random.uniform(5,15))\n",
    "        print('Next')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tReadAsins(AsinList)\n",
    "    \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting product reviews\n",
    "def ReadAsins(AsinList):\n",
    "    #list of columns for resulting CSV file\n",
    "    column_names = ['ASIN','date','author','title','rating','body','helpful']   \n",
    "    processed_asins = {}\n",
    "    for asin in AsinList:\n",
    "        no_more_pages = False\n",
    "        pageNumber = 1 \n",
    "        while no_more_pages == False:\n",
    "            processed_asins[asin] = {'Latest reviews page processed':pageNumber}\n",
    "            print(\"Downloading and processing reviews for \"+asin)\n",
    "\n",
    "            results = getProductReviews(asin, pageNumber)\n",
    "            print(results)\n",
    "\n",
    "            if results:\n",
    "                df = pd.DataFrame(results, columns=column_names)\n",
    "                \n",
    "                # if file does not exist write with header \n",
    "                if not os.path.isfile('reviews.csv'):\n",
    "                    df.to_csv('reviews.csv',index=False, )\n",
    "                else: # else it exists so append without writing the header\n",
    "                    df.to_csv('reviews.csv',mode = 'a',header=False,index=False, columns=column_names)\n",
    "            else:\n",
    "                no_more_pages = True\n",
    "\n",
    "            #try next page\n",
    "            pageNumber += 1\n",
    "            sleep(random.uniform(1,3))\n",
    "            print('Next')\n",
    "            \n",
    "        processed_df = pd.DataFrame(processed_asins, index=[0])\n",
    "        if not os.path.isfile('processed.csv'):\n",
    "            df.to_csv('processed.csv',index=False, )\n",
    "        else: # else it exists so append without writing the header\n",
    "            df.to_csv('processed.csv',mode = 'a',header=False,index=False)\n",
    "    \n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ReadAsins(AsinList)\n",
    "    \n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
